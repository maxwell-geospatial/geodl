% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/unifiedFocalLoss.R
\name{defineMultiClassLossDS}
\alias{defineMultiClassLossDS}
\title{defineMultiClassLossDS}
\usage{
defineMultiClassLossDS(
  nCls = 3,
  dsWghts = c(1, 0.3, 0.3, 0.3),
  lambda = 0.5,
  gamma = 0.5,
  delta = 0.6,
  smooth = 1e-08,
  chnDim = TRUE,
  zeroStart = TRUE,
  clsWghtsDist = 1,
  clsWghtsReg = 1,
  useLogCosH = FALSE,
  device = "cuda"
)
}
\arguments{
\item{nCls}{number of classes being differentiated. Should be 1 for a binary classification
where only the positive case logit is returned. Default is 3.}

\item{dsWghts}{Vector of 4 weights. Weights to apply to the losses calculated at each spatial
resolution when using deep supervision. The default is c(.6, .2, .1, .1) where larger weights are
placed on the results at a higher spatial resolution.}

\item{lambda}{Term used to control the relative weighting of the distribution- and region-based
losses. Default is 0.5, or equal weighting between the losses. If lambda = 1, only the distribution-
based loss is considered. If lambda = 0, only the region-based loss is considered. Values between 0.5
and 1 put more weight on the distribution-based loss while values between 0 and 0.5 put more
weight on the region-based loss.}

\item{gamma}{Parameter that controls increased weighting applied to difficult-to-predict pixels (for
distribution-based losses) or difficult-to-predict classes (region-based losses). Default is 0, or no focal
weighting is applied.}

\item{delta}{Parameter that controls the relative weightings of false positive and false negative errors for
each class. Different weightings can be provided for each class. The default is 0.6, which results in prioritizing
false positive errors relative to false negative errors.}

\item{smooth}{Smoothing factor to avoid divide-by-zero errors and provide numeric stability. Default is 1e-8.
Recommend using the default.}

\item{chnDim}{TRUE or FALSE. Whether the channel dimension is included in the target tensor:
(Batch, Channel, Height, Width) as opposed to (Batch, Channel, Height, Width). If the channel dimension
is included, this should be set to TRUE. If it is not, this should be set to FALSE. Default is TRUE.}

\item{zeroStart}{TRUE or FALSE. If class indices start at 0 as opposed to 1, this should be set to
TRUE. This is required  to implement one-hot encoding since R starts indexing at 1. Default is TRUE.}

\item{clsWghtsDist}{Vector of class weights for use in calculating a weighted version of the CE loss.
Default is for all classes to be equally weighted.}

\item{clsWghtsReg}{Vector of class weights for use in calculating a weighted version of the
region-based loss. Default is for all classes to be equally weighted.}

\item{useLogCosH}{TRUE or FALSE. Whether or not to apply a logCosH transformation to the region-based
loss. Default is FALSE.}

\item{pred}{Tensor of predicted class logits. Should be of shape (mini-batch,
class, width, height) where the class dimension has a length equal to the number
of classes being differentiated. For a binary classification, output can be provided
as (mini-batch, class, width, height) or (mini-batch, width, height) if only the positive
case logit is returned.}

\item{target}{Tensor or predicted class indices from 0 to n-1 or 1 to n where n is the
number of classes. For a binary classification, only the positive case logit can be returned.
Shape can be (mini-batch, class, width, height) or (mini-batch, width, height)}
}
\value{
Loss metric for use in training process.
}
\description{
Define a loss for semantic segmentation using a modified unified focal loss framework as a subclass of torch::nn_module() when using deep supervision.
}
\details{
Implementation of modified version of the unified focal dice loss after:

Yeung, M., Sala, E., Sch√∂nlieb, C.B. and Rundo, L., 2022. Unified focal loss:
Generalising dice and cross entropy-based losses to handle class imbalanced
medical image segmentation. Computerized Medical Imaging and Graphics, 95, p.102026.

Modifications include (1) allowing users to define class weights for both the distribution-
based and region-based metrics, (2) using class weights as opposed to the symmetric and
asymmetric methods implemented by the authors, and (3) including an option to apply
a logcosh transform for the region-based loss.

This loss has three key hyperparameters that control its implementation. Lambda controls
the relative weight of the distribution- and region-based losses. Default is 0.5,
or equal weighting between the losses is applied. If lambda = 1, only the distribution-
based loss is considered. If lambda = 0, only the region-based loss is considered. Values between 0.5
and 1 put more weight on the distribution-based loss while values between 0 and 0.5 put more
weight on the region-based loss.

Gamma controls the application of focal loss and the application of
increased weight to difficult-to-predict pixels (for distribution-based losses) or difficult-to-predict
classes (region-based losses). Smaller gamma values put increased weight on difficult samples or classes.
Using a value of 1 equates to not using a focal adjustment.

The delta term controls the relative weight of
false positive and false negative errors for each class. The default is 0.6 for each class, which results in
placing a higher weight on false positive as opposed to false negative errors relative to that class.

By adjusting the lambda, gamma, delta, and class weight terms, the user can implement a variety of different loss metrics
including cross entropy loss, weighted cross entropy loss, focal cross entropy loss, focal weighted cross entropy loss,
Dice loss, focal Dice loss, Tversky loss, and focal Tversky loss. Please see the associated vignettes that discuss how
to parameterize the function to obtain different loss metrics.
}
