% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assessRaster.R
\name{assessRaster}
\alias{assessRaster}
\title{assessRaster}
\usage{
assessRaster(
  reference,
  predicted,
  multiclass = TRUE,
  mappings,
  positive_case = mappings[1]
)
}
\arguments{
\item{reference}{Single-band, categorical spatRaster object representing
the reference labels. Note that the reference and predicted data must have
the same extent, number of rows and columns, and coordinate reference system.}

\item{predicted}{Single-band, categorical spatRaster object representing the
predicted labels. Note that the reference and predicted data must have the '
same extent, number of rows and columns, and coordinate reference system.}

\item{mappings}{Vector of factor level names. These must be in the same order
as the factor levels so that they are correctly matched to the correct category.
If no mappings are provided, then the factor levels are used by default. This
parameter can be especially useful when using raster data as input as it
allows the grid codes to be associated with more meaningful labels.}

\item{positive_case}{Factor level associated with the positive case for a
binary classification. Default is the second factor level. This argument is
not used for multiclass classification.}
}
\value{
List object containing the resulting metrics. For multiclass assessment,
the confusion matrix is provided in the $ConfusionMatrix object, the aggregated
metrics are provided in the $Metrics object, class user's accuracies are provided
in the $UsersAccs object, class producer's accuracies are provided in the
$ProducersAccs object, and the list of classes are provided in the $Classes object.
For a binary classification, the confusion matrix is provided in the
$ConfusionMatrix object, the overall metrics are provided in the $Metrics object,
the classes are provided in the $Classes object, and the positive class label is
provided in the $PositiveCase object.
}
\description{
Assess semantic segmentation model using categorical raster grids (wall-to-wall
reference data and predictions)
}
\details{
This function will generate a set of summary metrics when provided
reference and predicted classes. For a multiclass classification problem
a confusion matrix is produced with the columns representing the reference
data and the rows representing the predictions. The following metrics are
calculated: overall accuracy (OA), 95\% confidence interval for OA
(OAU and OAL), the Kappa statistic, map image classification
efficacy (MICE), average class user's accuracy (aUA), average class
producer's accuracy (aPA), average class F1-score, overall error (Error),
allocation disagreement (Allocation), quantity disagreement (Quantity),
exchange disagreement (Exchange), and shift disagreement (shift). For average
class user's accuracy, producer's accuracy, and F1-score, macro-averaging
is used where all classes are equally weighted. For a multiclass classification
all class user's and producer's accuracies are also returned.

For a binary classification problem, a confusion matrix is returned
along with the following metrics: overall accuracy (OA), overall accuracy
95\% confidence interval (OAU and OAL), the Kappa statistic (Kappa), map
image classification efficacy (MICE), precision (Precision), recall (Recall),
F1-score (F1), negative predictive value (NPV), specificity (Specificity),
overall error (Error), allocation disagreement (Allocation), quantity
disagreement (Quantity), exchange disagreement (Exchange), and shift
disagreement (shift).

Results are returned as a list object. This function makes use of the caret,
diffeR, and rfUtilities packages.
}
