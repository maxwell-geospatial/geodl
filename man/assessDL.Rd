% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assessDL.R
\name{assessDL}
\alias{assessDL}
\title{assessDL}
\usage{
assessDL(
  dl,
  model,
  batchSize,
  size,
  nCls,
  mode,
  cCodes,
  cNames,
  usedDS,
  useCUDA,
  positive_case
)
}
\arguments{
\item{dl}{torch DataLoader object.}

\item{nCls}{number of classes being differentiated.}

\item{cCodes}{class indices as a vector of integer values equal in length to the number of
classes.}

\item{cNames}{class names as a vector of character strings with a length equal to the number of
classes and in the correct order. Class codes and names are matched by position in the
cCodes and cNames vectors.}

\item{positive_case}{Factor level associated with the positive case for a
binary classification. Default is the second factor level. This argument is
not used for multiclass classification.}

\item{multiclass}{TRUE or FALSE. If more than two classes are differentiated,
use TRUE. If only two classes are differentiated and there are positive and
background/negative classes, use FALSE. Default is TRUE.}
}
\value{
List object containing the resulting metrics. For multiclass assessment,
the confusion matrix is provided in the $ConfusionMatrix object, the aggregated
metrics are provided in the $Metrics object, class user's accuracies are provided
in the $UsersAccs object, class producer's accuracies are provided in the
$ProducersAccs object, and the list of classes are provided in the $Classes object.
For a binary classification, the confusion matrix is provided in the
$ConfusionMatrix object, the metrics are provided in the $Metrics object,
the classes are provided in the $Classes object, and the positive class label is
provided in the $PositiveCase object.
}
\description{
Assess semantic segmentation model using all samples in a DataLoader.
}
\details{
This function generates a set of summary metrics when provided
reference and predicted classes. For a multiclass classification problem
a confusion matrix is produced with the columns representing the reference
data and the rows representing the predictions. The following metrics are
calculated: overall accuracy (OA), the Kappa statistic, map image classification
efficacy (MICE), average class user's accuracy (aUA), average class
producer's accuracy (aPA), and average class F1-score (aF1). For average
class user's accuracy, producer's accuracy, and F1-score, macro-averaging
is used where all classes are equally weighted. For a multiclass classification
all class user's and producer's accuracies are also returned.

For a binary classification problem, a confusion matrix is returned
along with the following metrics: overall accuracy (OA), overall accuracy,
the Kappa statistic (Kappa), map
image classification efficacy (MICE), precision (Precision), recall (Recall),
F1-score (F1), negative predictive value (NPV), and specificity (Specificity).

Results are returned as a list object. This function makes use of the rfUtilities package.
}
